{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba41e2db-8c66-42ff-bf71-689ce27e8bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   book_id  user_id  rating\n",
      "0        1      314       5\n",
      "1        1      439       3\n",
      "2        1      588       5\n",
      "3        1     1169       4\n",
      "4        1     1185       4\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 23 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   id                         10000 non-null  int64  \n",
      " 1   book_id                    10000 non-null  int64  \n",
      " 2   best_book_id               10000 non-null  int64  \n",
      " 3   work_id                    10000 non-null  int64  \n",
      " 4   books_count                10000 non-null  int64  \n",
      " 5   isbn                       9300 non-null   object \n",
      " 6   isbn13                     9415 non-null   float64\n",
      " 7   authors                    10000 non-null  object \n",
      " 8   original_publication_year  9979 non-null   float64\n",
      " 9   original_title             9415 non-null   object \n",
      " 10  title                      10000 non-null  object \n",
      " 11  language_code              8916 non-null   object \n",
      " 12  average_rating             10000 non-null  float64\n",
      " 13  ratings_count              10000 non-null  int64  \n",
      " 14  work_ratings_count         10000 non-null  int64  \n",
      " 15  work_text_reviews_count    10000 non-null  int64  \n",
      " 16  ratings_1                  10000 non-null  int64  \n",
      " 17  ratings_2                  10000 non-null  int64  \n",
      " 18  ratings_3                  10000 non-null  int64  \n",
      " 19  ratings_4                  10000 non-null  int64  \n",
      " 20  ratings_5                  10000 non-null  int64  \n",
      " 21  image_url                  10000 non-null  object \n",
      " 22  small_image_url            10000 non-null  object \n",
      "dtypes: float64(3), int64(13), object(7)\n",
      "memory usage: 1.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34252 entries, 0 to 34251\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   tag_id    34252 non-null  int64 \n",
      " 1   tag_name  34252 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 535.3+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 999912 entries, 0 to 999911\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count   Dtype\n",
      "---  ------             --------------   -----\n",
      " 0   goodreads_book_id  999912 non-null  int64\n",
      " 1   tag_id             999912 non-null  int64\n",
      " 2   count              999912 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 22.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Загружаем данные\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "books = pd.read_csv('books.csv')\n",
    "tags = pd.read_csv('tags.csv')\n",
    "book_tags = pd.read_csv('book_tags.csv')\n",
    "\n",
    "# Быстрый обзор\n",
    "print(ratings.head())\n",
    "print(books.info())\n",
    "print(tags.info())\n",
    "print(book_tags.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca336926-3d6f-4ce0-8078-50d5d6346654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2792775</td>\n",
       "      <td>272</td>\n",
       "      <td>439023483</td>\n",
       "      <td>9.780439e+12</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>...</td>\n",
       "      <td>4780653</td>\n",
       "      <td>4942365</td>\n",
       "      <td>155254</td>\n",
       "      <td>66715</td>\n",
       "      <td>127936</td>\n",
       "      <td>560092</td>\n",
       "      <td>1481305</td>\n",
       "      <td>2706317</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4640799</td>\n",
       "      <td>491</td>\n",
       "      <td>439554934</td>\n",
       "      <td>9.780440e+12</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>...</td>\n",
       "      <td>4602479</td>\n",
       "      <td>4800065</td>\n",
       "      <td>75867</td>\n",
       "      <td>75504</td>\n",
       "      <td>101676</td>\n",
       "      <td>455024</td>\n",
       "      <td>1156318</td>\n",
       "      <td>3011543</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41865</td>\n",
       "      <td>41865</td>\n",
       "      <td>3212258</td>\n",
       "      <td>226</td>\n",
       "      <td>316015849</td>\n",
       "      <td>9.780316e+12</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>...</td>\n",
       "      <td>3866839</td>\n",
       "      <td>3916824</td>\n",
       "      <td>95009</td>\n",
       "      <td>456191</td>\n",
       "      <td>436802</td>\n",
       "      <td>793319</td>\n",
       "      <td>875073</td>\n",
       "      <td>1355439</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2657</td>\n",
       "      <td>2657</td>\n",
       "      <td>3275794</td>\n",
       "      <td>487</td>\n",
       "      <td>61120081</td>\n",
       "      <td>9.780061e+12</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>...</td>\n",
       "      <td>3198671</td>\n",
       "      <td>3340896</td>\n",
       "      <td>72586</td>\n",
       "      <td>60427</td>\n",
       "      <td>117415</td>\n",
       "      <td>446835</td>\n",
       "      <td>1001952</td>\n",
       "      <td>1714267</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4671</td>\n",
       "      <td>4671</td>\n",
       "      <td>245494</td>\n",
       "      <td>1356</td>\n",
       "      <td>743273567</td>\n",
       "      <td>9.780743e+12</td>\n",
       "      <td>F. Scott Fitzgerald</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>...</td>\n",
       "      <td>2683664</td>\n",
       "      <td>2773745</td>\n",
       "      <td>51992</td>\n",
       "      <td>86236</td>\n",
       "      <td>197621</td>\n",
       "      <td>606158</td>\n",
       "      <td>936012</td>\n",
       "      <td>947718</td>\n",
       "      <td>https://images.gr-assets.com/books/1490528560m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1490528560s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  book_id  best_book_id  work_id  books_count       isbn        isbn13  \\\n",
       "0   1  2767052       2767052  2792775          272  439023483  9.780439e+12   \n",
       "1   2        3             3  4640799          491  439554934  9.780440e+12   \n",
       "2   3    41865         41865  3212258          226  316015849  9.780316e+12   \n",
       "3   4     2657          2657  3275794          487   61120081  9.780061e+12   \n",
       "4   5     4671          4671   245494         1356  743273567  9.780743e+12   \n",
       "\n",
       "                       authors  original_publication_year  \\\n",
       "0              Suzanne Collins                     2008.0   \n",
       "1  J.K. Rowling, Mary GrandPré                     1997.0   \n",
       "2              Stephenie Meyer                     2005.0   \n",
       "3                   Harper Lee                     1960.0   \n",
       "4          F. Scott Fitzgerald                     1925.0   \n",
       "\n",
       "                             original_title  ... ratings_count  \\\n",
       "0                          The Hunger Games  ...       4780653   \n",
       "1  Harry Potter and the Philosopher's Stone  ...       4602479   \n",
       "2                                  Twilight  ...       3866839   \n",
       "3                     To Kill a Mockingbird  ...       3198671   \n",
       "4                          The Great Gatsby  ...       2683664   \n",
       "\n",
       "  work_ratings_count  work_text_reviews_count  ratings_1  ratings_2  \\\n",
       "0            4942365                   155254      66715     127936   \n",
       "1            4800065                    75867      75504     101676   \n",
       "2            3916824                    95009     456191     436802   \n",
       "3            3340896                    72586      60427     117415   \n",
       "4            2773745                    51992      86236     197621   \n",
       "\n",
       "   ratings_3  ratings_4  ratings_5  \\\n",
       "0     560092    1481305    2706317   \n",
       "1     455024    1156318    3011543   \n",
       "2     793319     875073    1355439   \n",
       "3     446835    1001952    1714267   \n",
       "4     606158     936012     947718   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://images.gr-assets.com/books/1447303603m...   \n",
       "1  https://images.gr-assets.com/books/1474154022m...   \n",
       "2  https://images.gr-assets.com/books/1361039443m...   \n",
       "3  https://images.gr-assets.com/books/1361975680m...   \n",
       "4  https://images.gr-assets.com/books/1490528560m...   \n",
       "\n",
       "                                     small_image_url  \n",
       "0  https://images.gr-assets.com/books/1447303603s...  \n",
       "1  https://images.gr-assets.com/books/1474154022s...  \n",
       "2  https://images.gr-assets.com/books/1361039443s...  \n",
       "3  https://images.gr-assets.com/books/1361975680s...  \n",
       "4  https://images.gr-assets.com/books/1490528560s...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c221db99-a4cd-41d3-b5d1-dd07663d1aa4",
   "metadata": {},
   "source": [
    "Данные разреженные — много пользователей с минимальной историей.\n",
    "\n",
    "Проблема холодного старта: у новых или пассивных пользователей модель не сможет делать точные прогнозы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0174b94c-73b0-4dd9-8e6d-b6c1f8929885",
   "metadata": {},
   "source": [
    "Смещение популярности — небольшой набор тегов получает основную долю внимания.\n",
    "\n",
    "множество редко встречающихся тегов с очень малым числом взаимодействий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d04a9ea-c6c2-4c29-98de-a5bf9259a6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  original_title  avg_rating  num_ratings\n",
      "0                            NaN    4.820225           89\n",
      "1                            NaN    4.780000          100\n",
      "2                            NaN    4.780000          100\n",
      "3     Still Life with Woodpecker    4.777778           99\n",
      "4                            NaN    4.774194           93\n",
      "...                          ...         ...          ...\n",
      "9985                         NaN    2.430000          100\n",
      "9986                         NaN    2.350515           97\n",
      "9987                         NaN    2.312500           64\n",
      "9988                         NaN    2.235294           85\n",
      "9989                         NaN    1.960000          100\n",
      "\n",
      "[9990 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Неперсонализированная модель (Baseline)\n",
    "#книги с наибольшим средним рейтингом, если у них достаточно оценок (чтобы отсеять случайные всплески)\n",
    "\n",
    "# Считаем средний рейтинг и количество оценок по каждой книге \n",
    "book_stats = ratings.groupby('book_id').agg(\n",
    "    avg_rating=('rating', 'mean'),\n",
    "    num_ratings=('rating', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# === 3. Фильтруем: книги, у которых хотя бы 50 оценок ===\n",
    "popular_books = book_stats[book_stats['num_ratings'] >= 50]\n",
    "\n",
    "# === 4. Сортируем по среднему рейтингу (в порядке убывания) ===\n",
    "top_books = popular_books.sort_values(['avg_rating','num_ratings'], ascending=[False, False])\n",
    "\n",
    "# === 5. Присоединяем названия книг из books.csv ===\n",
    "top_books = top_books.merge(\n",
    "    books[['book_id', 'original_title']],\n",
    "    on='book_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# === 6. Выводим итоговый список самых популярных книг ===\n",
    "print(top_books[['original_title', 'avg_rating', 'num_ratings']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39621e3f-2e07-4c74-a16f-c6b0af327f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "585"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books['original_title'].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b142ca7e-fe00-4d7c-9a3b-2d6bc9ab4ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9415"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books['original_title'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5139e002-b896-402c-888f-89d7393efb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Группируем теги по книге, объединяя их в одну строку\n",
    "book_tag_texts = book_tags_full.groupby('goodreads_book_id')['tag_name'].apply(lambda x: ' '.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "836740d1-e305-4bea-bc12-dd5aca5bad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполним пропуски в оригинальных названиях\n",
    "books['original_title'] = books['original_title'].fillna(books['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5c20375-f73a-4908-ad55-c18c0160ee0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books['original_title'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc36ec4b-df47-42de-a6ea-546fa7ff67ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соединяем книги и их теги\n",
    "books_with_tags = books.merge(book_tag_texts, left_on='book_id', right_on='goodreads_book_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e667832-bc59-4fc5-b15f-5e2b24087421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Создаём текстовый профиль книги \n",
    "books_with_tags['text_profile'] = books_with_tags['original_title'].fillna('') + ' ' + books_with_tags['tag_name'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a47723c-0958-4550-a637-cd92f06a59fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    The Hunger Games favorites currently-reading y...\n",
       "Name: text_profile, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_with_tags['text_profile'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c029fa1-fe64-404d-a3cc-72ba32758c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Векторизация TF-IDF \n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(books_with_tags['text_profile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de56f488-b392-499e-bcb7-4b2d93a80155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>tag_name</th>\n",
       "      <th>text_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2792775</td>\n",
       "      <td>272</td>\n",
       "      <td>439023483</td>\n",
       "      <td>9.780439e+12</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>...</td>\n",
       "      <td>66715</td>\n",
       "      <td>127936</td>\n",
       "      <td>560092</td>\n",
       "      <td>1481305</td>\n",
       "      <td>2706317</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603s...</td>\n",
       "      <td>2767052</td>\n",
       "      <td>favorites currently-reading young-adult fictio...</td>\n",
       "      <td>The Hunger Games favorites currently-reading y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4640799</td>\n",
       "      <td>491</td>\n",
       "      <td>439554934</td>\n",
       "      <td>9.780440e+12</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>...</td>\n",
       "      <td>75504</td>\n",
       "      <td>101676</td>\n",
       "      <td>455024</td>\n",
       "      <td>1156318</td>\n",
       "      <td>3011543</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022s...</td>\n",
       "      <td>3</td>\n",
       "      <td>to-read favorites fantasy currently-reading yo...</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone to-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41865</td>\n",
       "      <td>41865</td>\n",
       "      <td>3212258</td>\n",
       "      <td>226</td>\n",
       "      <td>316015849</td>\n",
       "      <td>9.780316e+12</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>...</td>\n",
       "      <td>456191</td>\n",
       "      <td>436802</td>\n",
       "      <td>793319</td>\n",
       "      <td>875073</td>\n",
       "      <td>1355439</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443s...</td>\n",
       "      <td>41865</td>\n",
       "      <td>young-adult fantasy favorites vampires ya fict...</td>\n",
       "      <td>Twilight young-adult fantasy favorites vampire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2657</td>\n",
       "      <td>2657</td>\n",
       "      <td>3275794</td>\n",
       "      <td>487</td>\n",
       "      <td>61120081</td>\n",
       "      <td>9.780061e+12</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>...</td>\n",
       "      <td>60427</td>\n",
       "      <td>117415</td>\n",
       "      <td>446835</td>\n",
       "      <td>1001952</td>\n",
       "      <td>1714267</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680s...</td>\n",
       "      <td>2657</td>\n",
       "      <td>classics favorites to-read classic historical-...</td>\n",
       "      <td>To Kill a Mockingbird classics favorites to-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4671</td>\n",
       "      <td>4671</td>\n",
       "      <td>245494</td>\n",
       "      <td>1356</td>\n",
       "      <td>743273567</td>\n",
       "      <td>9.780743e+12</td>\n",
       "      <td>F. Scott Fitzgerald</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>...</td>\n",
       "      <td>86236</td>\n",
       "      <td>197621</td>\n",
       "      <td>606158</td>\n",
       "      <td>936012</td>\n",
       "      <td>947718</td>\n",
       "      <td>https://images.gr-assets.com/books/1490528560m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1490528560s...</td>\n",
       "      <td>4671</td>\n",
       "      <td>classics favorites fiction classic books-i-own...</td>\n",
       "      <td>The Great Gatsby classics favorites fiction cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  book_id  best_book_id  work_id  books_count       isbn        isbn13  \\\n",
       "0   1  2767052       2767052  2792775          272  439023483  9.780439e+12   \n",
       "1   2        3             3  4640799          491  439554934  9.780440e+12   \n",
       "2   3    41865         41865  3212258          226  316015849  9.780316e+12   \n",
       "3   4     2657          2657  3275794          487   61120081  9.780061e+12   \n",
       "4   5     4671          4671   245494         1356  743273567  9.780743e+12   \n",
       "\n",
       "                       authors  original_publication_year  \\\n",
       "0              Suzanne Collins                     2008.0   \n",
       "1  J.K. Rowling, Mary GrandPré                     1997.0   \n",
       "2              Stephenie Meyer                     2005.0   \n",
       "3                   Harper Lee                     1960.0   \n",
       "4          F. Scott Fitzgerald                     1925.0   \n",
       "\n",
       "                             original_title  ... ratings_1 ratings_2  \\\n",
       "0                          The Hunger Games  ...     66715    127936   \n",
       "1  Harry Potter and the Philosopher's Stone  ...     75504    101676   \n",
       "2                                  Twilight  ...    456191    436802   \n",
       "3                     To Kill a Mockingbird  ...     60427    117415   \n",
       "4                          The Great Gatsby  ...     86236    197621   \n",
       "\n",
       "   ratings_3  ratings_4  ratings_5  \\\n",
       "0     560092    1481305    2706317   \n",
       "1     455024    1156318    3011543   \n",
       "2     793319     875073    1355439   \n",
       "3     446835    1001952    1714267   \n",
       "4     606158     936012     947718   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://images.gr-assets.com/books/1447303603m...   \n",
       "1  https://images.gr-assets.com/books/1474154022m...   \n",
       "2  https://images.gr-assets.com/books/1361039443m...   \n",
       "3  https://images.gr-assets.com/books/1361975680m...   \n",
       "4  https://images.gr-assets.com/books/1490528560m...   \n",
       "\n",
       "                                     small_image_url  goodreads_book_id  \\\n",
       "0  https://images.gr-assets.com/books/1447303603s...            2767052   \n",
       "1  https://images.gr-assets.com/books/1474154022s...                  3   \n",
       "2  https://images.gr-assets.com/books/1361039443s...              41865   \n",
       "3  https://images.gr-assets.com/books/1361975680s...               2657   \n",
       "4  https://images.gr-assets.com/books/1490528560s...               4671   \n",
       "\n",
       "                                            tag_name  \\\n",
       "0  favorites currently-reading young-adult fictio...   \n",
       "1  to-read favorites fantasy currently-reading yo...   \n",
       "2  young-adult fantasy favorites vampires ya fict...   \n",
       "3  classics favorites to-read classic historical-...   \n",
       "4  classics favorites fiction classic books-i-own...   \n",
       "\n",
       "                                        text_profile  \n",
       "0  The Hunger Games favorites currently-reading y...  \n",
       "1  Harry Potter and the Philosopher's Stone to-re...  \n",
       "2  Twilight young-adult fantasy favorites vampire...  \n",
       "3  To Kill a Mockingbird classics favorites to-re...  \n",
       "4  The Great Gatsby classics favorites fiction cl...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_with_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4d017bb-7e75-4477-8982-151f2bb2e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция поиска похожих книг\n",
    "def prepare_tfidf_neighbors(tfidf_matrix, n_neighbors=20, n_jobs=-1):\n",
    "    \n",
    "    nn = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine', algorithm='brute', n_jobs=n_jobs)\n",
    "    nn.fit(tfidf_matrix)\n",
    "    return nn\n",
    "\n",
    "def get_similar_books_nn(book_id, nn_model, books_with_tags, tfidf_matrix, N=5):\n",
    "    \"\"\"\n",
    "    Возвращает DataFrame похожих книг (N штук).\n",
    "    \"\"\"\n",
    "    print(f'Книги, похожие на книгу под номером {book_id}')\n",
    "    \n",
    "    # ПРОВЕРКА: есть ли книга в данных\n",
    "    book_mask = books_with_tags['book_id'] == book_id\n",
    "    if not book_mask.any():\n",
    "        print(f\" Книга {book_id} не найдена в books_with_tags\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Получаем индекс строки в матрице\n",
    "    idx = books_with_tags[book_mask].index[0]\n",
    "    \n",
    "    \n",
    "    # Поиск похожих книг\n",
    "    distances, indices = nn_model.kneighbors(tfidf_matrix[idx])\n",
    "    sims = 1.0 - distances.flatten()\n",
    "    closest = indices.flatten()[1:N+1]  # пропускаем саму книгу\n",
    "    \n",
    "    # Получаем информацию о похожих книгах\n",
    "    result = books_with_tags.iloc[closest][['book_id', 'original_title', 'authors']].copy()\n",
    "    result['similarity'] = sims[1:N+1]\n",
    "    \n",
    "    print(f\"Найдено {len(result)} похожих книг\")\n",
    "    return result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fa012bb-5697-4db4-bf8c-ae485940459b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Книги, похожие на книгу под номером 3\n",
      "Найдено 5 похожих книг\n",
      "   book_id                            original_title  \\\n",
      "0    15881   Harry Potter and the Chamber of Secrets   \n",
      "1        5  Harry Potter and the Prisoner of Azkaban   \n",
      "2        1    Harry Potter and the Half-Blood Prince   \n",
      "3        6       Harry Potter and the Goblet of Fire   \n",
      "4   136251      Harry Potter and the Deathly Hallows   \n",
      "\n",
      "                                   authors  similarity  \n",
      "0              J.K. Rowling, Mary GrandPré    0.938596  \n",
      "1  J.K. Rowling, Mary GrandPré, Rufus Beck    0.927669  \n",
      "2              J.K. Rowling, Mary GrandPré    0.923824  \n",
      "3              J.K. Rowling, Mary GrandPré    0.919589  \n",
      "4              J.K. Rowling, Mary GrandPré    0.913415  \n"
     ]
    }
   ],
   "source": [
    "# Проверим на практике\n",
    "nn_model = prepare_tfidf_neighbors(tfidf_matrix, n_neighbors=20)\n",
    "\n",
    "similar_books = get_similar_books_nn(3, nn_model, books_with_tags, tfidf_matrix, N=5)\n",
    "\n",
    "print(similar_books.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6dcec227-71df-4e74-8fb7-8c7de379c865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестируем первую книгу в данных: ID = 2767052\n",
      "Книги, похожие на книгу под номером 2767052\n",
      "Найдено 5 похожих книг\n",
      "    book_id                                     original_title  \\\n",
      "0   7260188                                         Mockingjay   \n",
      "1   6148028                                      Catching Fire   \n",
      "2   7938275                           The Hunger Games Box Set   \n",
      "3  13027304                     The Hunger Games Tribute Guide   \n",
      "4  11742691  The Hunger Games: Official Illustrated Movie C...   \n",
      "\n",
      "           authors  similarity  \n",
      "0  Suzanne Collins    0.944355  \n",
      "1  Suzanne Collins    0.929562  \n",
      "2  Suzanne Collins    0.916654  \n",
      "3      Emily Seife    0.692629  \n",
      "4        Kate Egan    0.686390  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "first_id = books_with_tags['book_id'].iloc[0]\n",
    "print(f\"Тестируем первую книгу в данных: ID = {first_id}\")\n",
    "\n",
    "similar_books = get_similar_books_nn(first_id, nn_model, books_with_tags, tfidf_matrix, N=5)\n",
    "print(similar_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9358d1a-7a6e-42cd-8c23-36b74f657d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 981756 entries, 0 to 981755\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count   Dtype\n",
      "---  ------   --------------   -----\n",
      " 0   book_id  981756 non-null  int64\n",
      " 1   user_id  981756 non-null  int64\n",
      " 2   rating   981756 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 22.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ratings.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31009c36-d47b-4755-aa0b-91b09e59530d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Матрица с явными оценками ===\n",
      "Размерность: (53424, 10000)\n",
      "Количество оценок: 979478\n",
      "Разреженность: 99.82%\n",
      "\n",
      "Первые 5 строк и 10 столбцов:\n",
      "book_id   1    2    3    4    5    6    7    8    9    10\n",
      "user_id                                                  \n",
      "1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "5        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "#Матрица с явными оценками\n",
    "user_book_rating_matrix = ratings.pivot_table(\n",
    "    index='user_id',\n",
    "    columns='book_id',\n",
    "    values='rating',\n",
    "    fill_value=0  # или fill_value=None чтобы оставить NaN\n",
    ")\n",
    "\n",
    "print(\"=== Матрица с явными оценками ===\")\n",
    "print(f\"Размерность: {user_book_rating_matrix.shape}\")\n",
    "print(f\"Количество оценок: {(user_book_rating_matrix > 0).sum().sum()}\")\n",
    "print(f\"Разреженность: {(1 - (user_book_rating_matrix > 0).sum().sum() / (user_book_rating_matrix.shape[0] * user_book_rating_matrix.shape[1])) * 100:.2f}%\")\n",
    "print(\"\\nПервые 5 строк и 10 столбцов:\")\n",
    "print(user_book_rating_matrix.iloc[:5, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57514d4d-9c89-4f66-ac04-992203083367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_topk_item_neighbors(ratings_matrix, top_k=50, metric='cosine', n_jobs=-1):\n",
    "    \n",
    "    # 1. Просто транспонируем существующую матрицу (уже с нулями вместо NaN)\n",
    "    sparse_matrix = csr_matrix(ratings_matrix.values.T, dtype=np.float32)\n",
    "    \n",
    "    print(f\"Размер разреженной матрицы: {sparse_matrix.shape}\")\n",
    "    print(f\"Количество ненулевых элементов: {sparse_matrix.nnz}\")\n",
    "    \n",
    "    # 2. Проверяем, что у нас достаточно данных\n",
    "    n_items = sparse_matrix.shape[0]\n",
    "    if n_items <= top_k:\n",
    "        print(\"Предупреждение: количество книг меньше top_k\")\n",
    "        return {}\n",
    "    \n",
    "    # 3. Находим ближайших соседей\n",
    "    k = min(top_k + 1, n_items)  # +1 чтобы исключить саму книгу\n",
    "    \n",
    "    nn = NearestNeighbors(n_neighbors=k, metric=metric, algorithm='brute', n_jobs=1)\n",
    "    nn.fit(sparse_matrix)\n",
    "    \n",
    "    distances, indices = nn.kneighbors(sparse_matrix)\n",
    "    similarities = 1.0 - distances\n",
    "    \n",
    "    # 4. Собираем результаты\n",
    "    item_ids = list(ratings_matrix.columns)  # ID книг\n",
    "    topk_dict = {}\n",
    "    \n",
    "    for i, item_id in enumerate(item_ids):\n",
    "        # Пропускаем саму книгу и берем top_k соседей\n",
    "        neighbor_indices = indices[i][1:top_k+1]  # пропускаем первый (сама книга)\n",
    "        neighbor_similarities = similarities[i][1:top_k+1]\n",
    "        \n",
    "        neighbors = []\n",
    "        for idx, sim in zip(neighbor_indices, neighbor_similarities):\n",
    "            if idx < len(item_ids):  # проверка границ\n",
    "                neighbors.append((item_ids[idx], float(sim)))\n",
    "        \n",
    "        topk_dict[item_id] = neighbors\n",
    "    \n",
    "    return topk_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c489156-82d1-4456-b4aa-d0102ea24106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция предсказания оценки (улучшеная)\n",
    "def predict_rating_item_based(user_id, book_id, ratings_matrix, topk_neighbors, k=10):\n",
    "    \n",
    "    # Оптимизация: глобальное среднее вычисляем один раз и кэшируем\n",
    "    global_mean = ratings_matrix.values.mean()  # быстрее чем stack() для больших матриц\n",
    "    \n",
    "    # Быстрая проверка наличия книги и пользователя\n",
    "    if book_id not in topk_neighbors:\n",
    "        # Если у нас нет информации о похожих книгах — вернём среднее пользователя или глобальное\n",
    "        if user_id in ratings_matrix.index:\n",
    "            user_ratings = ratings_matrix.loc[user_id]\n",
    "            # Используем встроенные методы pandas для скорости\n",
    "            user_mean = user_ratings.replace(0, np.nan).mean()  # заменяем 0 на NaN для игнорирования\n",
    "            if not np.isnan(user_mean):\n",
    "                return float(user_mean)\n",
    "        return float(global_mean)\n",
    "\n",
    "    if user_id not in ratings_matrix.index:\n",
    "        # Новый пользователь — возвращаем популярное/среднее (холодный старт)\n",
    "        return float(global_mean)\n",
    "    \n",
    "    neighbors = topk_neighbors[book_id][:k]\n",
    "    weighted_sum = 0.0\n",
    "    sim_sum = 0.0\n",
    "    \n",
    "    # Оптимизация: получаем данные пользователя один раз\n",
    "    user_ratings_series = ratings_matrix.loc[user_id]\n",
    "    \n",
    "    for neigh_item, sim in neighbors:\n",
    "        # Быстрая проверка наличия книги у пользователя\n",
    "        if neigh_item in user_ratings_series.index:\n",
    "            rating = user_ratings_series[neigh_item]\n",
    "            # Проверяем что оценка ненулевая (не пропуск)\n",
    "            if rating != 0:  # так как у вас нули вместо NaN\n",
    "                weighted_sum += sim * rating\n",
    "                sim_sum += sim\n",
    "    \n",
    "    if sim_sum == 0:\n",
    "        # Нет пересечения с соседями — fallback\n",
    "        user_mean = user_ratings_series.replace(0, np.nan).mean()\n",
    "        if not np.isnan(user_mean):\n",
    "            return float(user_mean)\n",
    "        return float(global_mean)\n",
    "    \n",
    "    return float(weighted_sum / sim_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "595ef4dd-20aa-4fbb-95dd-ea472ae51b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестирование Item-Based Collaborative Filtering\n",
      "Размер разреженной матрицы: (10000, 53424)\n",
      "Количество ненулевых элементов: 979478\n",
      "Предсказанная оценка (явные рейтинги): 3.583\n"
     ]
    }
   ],
   "source": [
    "# Тестируем на примере\n",
    "test_user_id = 3980  \n",
    "test_book_id = 55    \n",
    "\n",
    "print(\"Тестирование Item-Based Collaborative Filtering\")\n",
    "\n",
    "item_similarity_test = calculate_topk_item_neighbors(user_book_rating_matrix, top_k=50, metric='cosine')\n",
    "\n",
    "# Предсказание\n",
    "prediction_1 = predict_rating_item_based(\n",
    "    test_user_id, test_book_id, \n",
    "    user_book_rating_matrix, item_similarity_test, k=10\n",
    ")\n",
    "\n",
    "print(f\"Предсказанная оценка (явные рейтинги): {prediction_1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7dbfeca-5e89-49d2-8aeb-86123727923c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение SVD...\n",
      "Обучение завершено\n",
      "RMSE: 0.8402\n",
      "RMSE: 0.8402348403007891\n",
      "Пример уникальных предсказаний (первые 10 уникальных): [1.0, 1.0128, 1.0179, 1.0209, 1.0317, 1.0379, 1.0389, 1.0844, 1.0878, 1.1059]\n"
     ]
    }
   ],
   "source": [
    "# Подготовка данных для библиотеки Surprise\n",
    "data_for_surprise = ratings[['user_id', 'book_id', 'rating']]\n",
    "# SVD: подготовка данных, диагностика, корректный генератор рекомендаций \n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# проверить: рейтинги числовые \n",
    "data_for_surprise['rating'] = pd.to_numeric(data_for_surprise['rating'], errors='coerce')\n",
    "data_for_surprise = data_for_surprise.dropna(subset=['rating'])\n",
    "data_for_surprise['rating'] = data_for_surprise['rating'].astype(float)\n",
    "\n",
    "# Создаём датасет в surprise \n",
    "reader = Reader(rating_scale=(data_for_surprise['rating'].min(), data_for_surprise['rating'].max()))\n",
    "data = Dataset.load_from_df(data_for_surprise[['user_id', 'book_id', 'rating']], reader)\n",
    "\n",
    "# Разбиваем train/test \n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "#  Создаём модель SVD \n",
    "model = SVD(n_factors=50, n_epochs=20, biased=True, random_state=42, verbose=False)\n",
    "\n",
    "print(\"Обучение SVD...\")\n",
    "model.fit(trainset)\n",
    "print(\"Обучение завершено\")\n",
    "\n",
    "#  Проверка предсказаний на тесте \n",
    "predictions = model.test(testset)\n",
    "rmse = accuracy.rmse(predictions, verbose=True)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "#  Диагностика: какие уникальные предсказания? \n",
    "pred_values = [round(p.est, 4) for p in predictions]\n",
    "unique_preds = sorted(set(pred_values))[:10]\n",
    "print(\"Пример уникальных предсказаний (первые 10 уникальных):\", unique_preds[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b6f237f-e594-47f2-9225-e992490d7acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуем функцию генерации рекомендаций\n",
    "# Получение топ-N рекомендаций от SVD (без предсказаний для неизвестных айтемов) \n",
    "def get_svd_recommendations(model, trainset, user_raw_id, books_df, N=10):\n",
    "    \"\"\"\n",
    "    model: обученная модель surprise.SVD\n",
    "    trainset: trainset, на котором обучали (объект surprise.trainset)\n",
    "    user_raw_id: id пользователя в том же формате, что и в исходном DataFrame\n",
    "    books_df: DataFrame с информацией о книгах (columns содержит 'book_id' в том же формате)\n",
    "    Возвращает DataFrame с топ-N рекомендациями (book_id, title, est_rating)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        inner_uid = trainset.to_inner_uid(user_raw_id)  # если пользователя нет — выбросит ValueError\n",
    "    except ValueError:\n",
    "        # Холодный старт пользователя: вернуть топ популярных книг (по среднему рейтингу в датасете)\n",
    "        popular = books_df.merge(\n",
    "            data_for_surprise.groupby('book_id')['rating'].mean().reset_index(),\n",
    "            left_on='book_id', right_on='book_id', how='left'\n",
    "        ).sort_values('rating', ascending=False)\n",
    "        return popular[['book_id', 'original_title', 'authors', 'rating']].head(N)\n",
    "\n",
    "    # items, которые есть в trainset (inner ids)\n",
    "    all_inner_items = list(trainset.all_items())\n",
    "    # items, которые пользователь уже оценил (inner ids)\n",
    "    rated_by_user = set([j for (j, _) in trainset.ur[inner_uid]])\n",
    "    candidates = [i for i in all_inner_items if i not in rated_by_user]\n",
    "\n",
    "    preds = []\n",
    "    for inner_i in candidates:\n",
    "        raw_i = trainset.to_raw_iid(inner_i)\n",
    "        pred = model.predict(user_raw_id, raw_i)\n",
    "        preds.append((raw_i, pred.est))\n",
    "\n",
    "    preds.sort(key=lambda x: x[1], reverse=True)\n",
    "    top = preds[:N]\n",
    "    top_df = pd.DataFrame(top, columns=['book_id', 'predicted_rating'])\n",
    "    \n",
    "    top_df = top_df.merge(books_df, left_on='book_id', right_on='book_id', how='left')\n",
    "    return top_df[['book_id', 'original_title', 'authors', 'predicted_rating']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72911ea1-476c-44c3-8406-0a54e1e04e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   book_id              original_title                        authors  \\\n",
      "0     6920                         NaN                            NaN   \n",
      "1     9566  Still Life with Woodpecker                    Tom Robbins   \n",
      "2     3628                         NaN                            NaN   \n",
      "3     3395                         NaN                            NaN   \n",
      "4     2244                         NaN                            NaN   \n",
      "5     9842                         NaN                            NaN   \n",
      "6     6590                         NaN                            NaN   \n",
      "7     8854                         NaN                            NaN   \n",
      "8     3885  The Taste of Home Cookbook  Janet Briggs, Beth Wittlinger   \n",
      "9     5384                         NaN                            NaN   \n",
      "\n",
      "   predicted_rating  \n",
      "0          4.982233  \n",
      "1          4.980175  \n",
      "2          4.947803  \n",
      "3          4.943862  \n",
      "4          4.940099  \n",
      "5          4.925761  \n",
      "6          4.906972  \n",
      "7          4.900614  \n",
      "8          4.888074  \n",
      "9          4.887620  \n"
     ]
    }
   ],
   "source": [
    "# Пример использования:\n",
    "recs = get_svd_recommendations(model, trainset, user_raw_id=378, books_df=books)\n",
    "print(recs.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd07c44-9d8b-4963-8b42-622aa60492b9",
   "metadata": {},
   "source": [
    "#### Сделаем несколько оптимизированых улучшеных моделей для сравнения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40216522-63e2-4134-801a-fedd039694fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# ПАРАМЕТРЫ ОЦЕНКИ \n",
    "# -------------------------\n",
    "OUT_DIR = \".\"                   # папка для результатов\n",
    "RANDOM_STATE = 42\n",
    "TOP_CANDIDATES = 2000           # количество самых популярных книг для кандидатов\n",
    "SVD_FACTORS = 50                # количество компонент для TruncatedSVD\n",
    "TOPK_LIST = [5, 10, 20]         # K для Precision@K и других метрик\n",
    "RATING_THRESHOLD = 4.0          # оценка >= считается релевантной\n",
    "MAX_EVAL_USERS = 2000           # ограничение пользователей для оценки (для скорости)\n",
    "# -------------------------\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "598fe1ab-6faa-490b-bd2f-4aa571d4672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out(ratings_df, seed=RANDOM_STATE):\n",
    "    \"\"\"\n",
    "    Разделение данных по схеме leave-one-out: для каждого пользователя \n",
    "    одна случайная оценка идет в тест, остальные в тренировочную выборку\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    train_rows, test_rows = [], []\n",
    "    for uid, g in ratings_df.groupby('user_id'):\n",
    "        if len(g) < 2:\n",
    "            train_rows.append(g)\n",
    "            continue\n",
    "        tidx = np.random.choice(g.index, size=1, replace=False)\n",
    "        mask = g.index.isin(tidx)\n",
    "        test_rows.append(g[mask])\n",
    "        train_rows.append(g[~mask])\n",
    "    train = pd.concat(train_rows).reset_index(drop=True)\n",
    "    test = pd.concat(test_rows).reset_index(drop=True)\n",
    "    return train, test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2f527c8-689a-48f1-aaa1-a00dfbe24c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Реализация метрик Precision@K, Recall@K, nDCG@K\n",
    "def precision_at_k(recommended, relevant, k=5):\n",
    "   \n",
    "    \"\"\"Доля релевантных книг среди рекомендованных\"\"\"\n",
    "   \n",
    "    recommended_k = recommended[:k]\n",
    "    hits = len(set(recommended_k) & set(relevant))\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(recommended, relevant, k=5):\n",
    "    \n",
    "    \"\"\"Доля найденных релевантных книг среди всех релевантных\"\"\"\n",
    "    recommended_k = recommended[:k]\n",
    "    hits = len(set(recommended_k) & set(relevant))\n",
    "    return hits / len(relevant) if len(relevant) > 0 else 0\n",
    "\n",
    "def ndcg_at_k(recommended, relevant, k=5):\n",
    "    \"\"\"Normalized Discounted Cumulative Gain\"\"\"\n",
    "    recommended_k = recommended[:k]\n",
    "    dcg = sum([(1 / np.log2(i + 2)) if rec in relevant else 0 for i, rec in enumerate(recommended_k)])\n",
    "    ideal_dcg = sum([1 / np.log2(i + 2) for i in range(min(k, len(relevant)))])\n",
    "    return dcg / ideal_dcg if ideal_dcg > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba07b311-9e91-4fee-be2a-97971dc95e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_popularity_metrics(train_df, test_df, top_candidates, eval_users, K_list, rating_threshold):\n",
    "    \"\"\"\n",
    "    Оценка базовой модели популярности: рекомендует самые популярные книги\n",
    "    \"\"\"\n",
    "    pop_cand = top_candidates\n",
    "    # Создаем карту уже просмотренных книг для каждого пользователя\n",
    "    sub = train_df[train_df['user_id'].isin(eval_users)]\n",
    "    seen_map = {u:set(g['book_id'].tolist()) for u,g in sub.groupby('user_id')}\n",
    "    \n",
    "    results = []\n",
    "    for K in K_list:\n",
    "        precs, recs, ndcs = [], [], []\n",
    "        for user in eval_users:\n",
    "            user_test = test_df[test_df['user_id']==user]\n",
    "            relevant = set(user_test[user_test['rating'] >= rating_threshold]['book_id'].tolist())\n",
    "            if len(relevant) == 0: \n",
    "                continue\n",
    "            seen = seen_map.get(user, set())\n",
    "            # Рекомендуем самые популярные книги, которые пользователь еще не видел\n",
    "            rec_list = [p for p in pop_cand if p not in seen][:K]\n",
    "            precs.append(precision_at_k(rec_list, relevant, K))\n",
    "            recs.append(recall_at_k(rec_list, relevant, K))\n",
    "            ndcs.append(ndcg_at_k(rec_list, relevant, K))\n",
    "        \n",
    "        results.append({\n",
    "            'model':'Popularity',\n",
    "            'K':K,\n",
    "            'precision_mean':float(np.nanmean(precs)) if len(precs)>0 else 0.0,\n",
    "            'recall_mean':float(np.nanmean(recs)) if len(recs)>0 else np.nan,\n",
    "            'ndcg_mean':float(np.nanmean(ndcs)) if len(ndcs)>0 else np.nan,\n",
    "            'n_eval_users':len(precs)\n",
    "        })\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ba1021cf-88ec-4dad-b808-7a122670e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vectorized_itemcf(train_df, test_df, top_candidates, eval_users, K_list, rating_threshold):\n",
    "    \"\"\"\n",
    "    Оценка Item-Based Collaborative Filtering с векторизацией\n",
    "    \"\"\"\n",
    "    # Ограничиваем тренировочные данные только кандидатскими книгами\n",
    "    train_cand = train_df[train_df['book_id'].isin(top_candidates)].reset_index(drop=True)\n",
    "    users = train_cand['user_id'].unique()\n",
    "    items = train_cand['book_id'].unique()\n",
    "    user_to_idx = {u:i for i,u in enumerate(users)}\n",
    "    item_to_idx = {it:i for i,it in enumerate(items)}\n",
    "    idx_to_item = {i:it for it,i in item_to_idx.items()}\n",
    "    \n",
    "    # Строим матрицу предметы×пользователи\n",
    "    rows = train_cand['book_id'].map(item_to_idx).values\n",
    "    cols = train_cand['user_id'].map(user_to_idx).values\n",
    "    vals = train_cand['rating'].values\n",
    "    mat_item_user = csr_matrix((vals, (rows, cols)), shape=(len(items), len(users)), dtype=np.float32)\n",
    "    \n",
    "    # Строим матрицу W: eval_users × n_items (оценки eval_users среди кандидатов)\n",
    "    eval_user_to_row = {u:i for i,u in enumerate(eval_users)}\n",
    "    n_eval = len(eval_users); n_items = len(items)\n",
    "    W_rows = []; W_cols = []; W_vals = []\n",
    "    \n",
    "    for r in train_cand.itertuples(index=False):\n",
    "        row = eval_user_to_row.get(r.user_id, None)\n",
    "        if row is not None:\n",
    "            W_rows.append(row); W_cols.append(item_to_idx[r.book_id]); W_vals.append(r.rating)\n",
    "    \n",
    "    if len(W_vals) == 0:\n",
    "        raise RuntimeError(\"Нет тренировочных взаимодействий для eval пользователей среди кандидатов. Уменьшите TOP_CANDIDATES.\")\n",
    "    \n",
    "    W = csr_matrix((W_vals, (W_rows, W_cols)), shape=(n_eval, n_items), dtype=np.float32)\n",
    "    \n",
    "    # user_profiles = W dot mat_item_user -> (n_eval x n_users)\n",
    "    user_profiles = W.dot(mat_item_user)\n",
    "    user_profiles = user_profiles.toarray() if hasattr(user_profiles, \"toarray\") else np.asarray(user_profiles)\n",
    "    \n",
    "    # scores_matrix = mat_item_user dot user_profiles.T -> (n_items x n_eval)\n",
    "    scores_matrix = mat_item_user.dot(user_profiles.T)\n",
    "    scores = scores_matrix.toarray() if hasattr(scores_matrix, \"toarray\") else np.asarray(scores_matrix)\n",
    "    \n",
    "    # Карта уже просмотренных книг\n",
    "    sub = train_df[train_df['user_id'].isin(eval_users)]\n",
    "    seen_map = {u:set(g['book_id'].tolist()) for u,g in sub.groupby('user_id')}\n",
    "    \n",
    "    # Вычисляем метрики\n",
    "    results = []\n",
    "    for K in K_list:\n",
    "        precs, recs, ndcs = [], [], []\n",
    "        for ui,user in enumerate(eval_users):\n",
    "            user_test = test_df[test_df['user_id']==user]\n",
    "            relevant = set(user_test[user_test['rating'] >= rating_threshold]['book_id'].tolist())\n",
    "            if len(relevant) == 0: \n",
    "                continue\n",
    "                \n",
    "            col_scores = scores[:, ui].copy()\n",
    "            seen = seen_map.get(user, set())\n",
    "            \n",
    "            # Исключаем уже просмотренные книги\n",
    "            for b in seen:\n",
    "                if b in item_to_idx:\n",
    "                    col_scores[item_to_idx[b]] = -np.inf\n",
    "            \n",
    "            # Выбираем топ-K индексов\n",
    "            topN = min(K, len(col_scores))\n",
    "            idxs = np.argpartition(-col_scores, topN-1)[:topN]\n",
    "            idxs = idxs[np.argsort(-col_scores[idxs])]\n",
    "            recs_list = [idx_to_item[i] for i in idxs]\n",
    "            \n",
    "            precs.append(precision_at_k(recs_list, relevant, K))\n",
    "            recs.append(recall_at_k(recs_list, relevant, K))\n",
    "            ndcs.append(ndcg_at_k(recs_list, relevant, K))\n",
    "            \n",
    "        results.append({\n",
    "            'model':'ItemCF',\n",
    "            'K':K,\n",
    "            'precision_mean':float(np.nanmean(precs)) if len(precs)>0 else 0.0,\n",
    "            'recall_mean':float(np.nanmean(recs)) if len(recs)>0 else np.nan,\n",
    "            'ndcg_mean':float(np.nanmean(ndcs)) if len(ndcs)>0 else np.nan,\n",
    "            'n_eval_users':len(precs)\n",
    "        })\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc8554f5-9068-4609-b3f4-6ea06192b7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_svd_metrics(train_df, test_df, top_candidates, eval_users, K_list, rating_threshold, n_factors):\n",
    "    \"\"\"\n",
    "    Оценка SVD модели (матричная факторизация)\n",
    "    \"\"\"\n",
    "    # Строим уменьшенную тренировочную матрицу на кандидатах\n",
    "    train_cand = train_df[train_df['book_id'].isin(top_candidates)].reset_index(drop=True)\n",
    "    users = train_cand['user_id'].unique()\n",
    "    items = train_cand['book_id'].unique()\n",
    "    user_to_idx = {u:i for i,u in enumerate(users)}\n",
    "    item_to_idx = {it:i for i,it in enumerate(items)}\n",
    "    idx_to_item = {i:it for it,i in item_to_idx.items()}\n",
    "    \n",
    "    rows = train_cand['book_id'].map(item_to_idx).values\n",
    "    cols = train_cand['user_id'].map(user_to_idx).values\n",
    "    vals = train_cand['rating'].values\n",
    "    \n",
    "    if len(rows) == 0:\n",
    "        raise RuntimeError(\"Нет тренировочных взаимодействий после фильтрации по топ кандидатам.\")\n",
    "    \n",
    "    mat_item_user = csr_matrix((vals, (rows, cols)), shape=(len(items), len(users)), dtype=np.float32)\n",
    "    mat_user_item = mat_item_user.T  # (n_users x n_items)\n",
    "    \n",
    "    n_comp = min(n_factors, min(mat_user_item.shape)-1)\n",
    "    if n_comp <= 0:\n",
    "        raise RuntimeError(\"Слишком маленькая матрица для SVD; нужно уменьшить TOP_CANDIDATES или factors\")\n",
    "    \n",
    "    # Обучаем TruncatedSVD\n",
    "    svd = TruncatedSVD(n_components=n_comp, random_state=RANDOM_STATE)\n",
    "    user_factors = svd.fit_transform(mat_user_item)   # (n_users, n_comp)\n",
    "    item_factors = svd.components_.T                  # (n_items, n_comp)\n",
    "    \n",
    "    # Подготавливаем eval пользователей, которые есть в маппинге\n",
    "    eval_present = [u for u in eval_users if u in user_to_idx]\n",
    "    eval_user_idxs = [user_to_idx[u] for u in eval_present]\n",
    "    \n",
    "    if len(eval_present) == 0:\n",
    "        raise RuntimeError(\"Нет eval пользователей в SVD маппинге. Уменьшить TOP_CANDIDATES или обеспечить пересечение.\")\n",
    "    \n",
    "    user_factors_eval = user_factors[eval_user_idxs]  # (n_eval_present, n_comp)\n",
    "    scores_svd = item_factors.dot(user_factors_eval.T)  # (n_items x n_eval_present)\n",
    "    \n",
    "    # Карта просмотренных книг для eval_present\n",
    "    sub = train_df[train_df['user_id'].isin(eval_present)]\n",
    "    seen_map = {u:set(g['book_id'].tolist()) for u,g in sub.groupby('user_id')}\n",
    "    \n",
    "    # Вычисляем метрики\n",
    "    results = []\n",
    "    for K in K_list:\n",
    "        precs, recs, ndcs = [], [], []\n",
    "        for ui, user in enumerate(eval_present):\n",
    "            user_test = test_df[test_df['user_id']==user]\n",
    "            relevant = set(user_test[user_test['rating'] >= rating_threshold]['book_id'].tolist())\n",
    "            if len(relevant) == 0: continue\n",
    "            \n",
    "            col_scores = scores_svd[:, ui].copy()\n",
    "            seen = seen_map.get(user, set())\n",
    "            \n",
    "            # Исключаем просмотренные\n",
    "            for b in seen:\n",
    "                if b in item_to_idx:\n",
    "                    col_scores[item_to_idx[b]] = -np.inf\n",
    "            \n",
    "            topN = min(K, len(col_scores))\n",
    "            idxs = np.argpartition(-col_scores, topN-1)[:topN]\n",
    "            idxs = idxs[np.argsort(-col_scores[idxs])]\n",
    "            recs_list = [idx_to_item[i] for i in idxs]\n",
    "            \n",
    "            precs.append(precision_at_k(recs_list, relevant, K))\n",
    "            recs.append(recall_at_k(recs_list, relevant, K))\n",
    "            ndcs.append(ndcg_at_k(recs_list, relevant, K))\n",
    "            \n",
    "        results.append({\n",
    "            'model':'SVD',\n",
    "            'K':K,\n",
    "            'precision_mean':float(np.nanmean(precs)) if len(precs)>0 else 0.0,\n",
    "            'recall_mean':float(np.nanmean(recs)) if len(recs)>0 else np.nan,\n",
    "            'ndcg_mean':float(np.nanmean(ndcs)) if len(ndcs)>0 else np.nan,\n",
    "            'n_eval_users':len(precs)\n",
    "        })\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bbf7f8f8-4d32-4e2c-9dcf-8067419deb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recommendation_systems(ratings):\n",
    "    \"\"\"\n",
    "    Основная функция оценки рекомендательных систем\n",
    "    \"\"\"\n",
    "    print(\"Начинаем оценку рекомендательных систем...\")\n",
    "    \n",
    "    print(\"Делаем leave-one-out разделение...\")\n",
    "    t0 = time.time()\n",
    "    train_df, test_df = leave_one_out(ratings, seed=RANDOM_STATE)\n",
    "    print(f\"Тренировочные данные: {len(train_df)}, Тестовые данные: {len(test_df)}, время: {time.time() - t0:.1f} сек\")\n",
    "\n",
    "    # Строим рейтинг популярности из тренировочных данных\n",
    "    pop = train_df.groupby('book_id').agg(\n",
    "        num_ratings=('rating','count'), \n",
    "        avg_rating=('rating','mean')\n",
    "    ).reset_index().sort_values(['num_ratings','avg_rating'], ascending=False)\n",
    "    \n",
    "    top_items = pop['book_id'].tolist()\n",
    "    top_candidates = top_items[:TOP_CANDIDATES]\n",
    "    print(f\"Топ кандидатов (количество): {len(top_candidates)}\")\n",
    "\n",
    "    # Выбираем пользователей для оценки: у которых тестовая оценка >= порога и тестовая книга среди кандидатов\n",
    "    test_rel = test_df[test_df['rating'] >= RATING_THRESHOLD]\n",
    "    eval_users_all = test_rel[test_rel['book_id'].isin(top_candidates)]['user_id'].unique().tolist()\n",
    "    print(f\"Доступные пользователи для оценки: {len(eval_users_all)}\")\n",
    "    \n",
    "    if MAX_EVAL_USERS is not None and len(eval_users_all) > MAX_EVAL_USERS:\n",
    "        rng = np.random.RandomState(RANDOM_STATE)\n",
    "        eval_users = list(rng.choice(eval_users_all, size=MAX_EVAL_USERS, replace=False))\n",
    "    else:\n",
    "        eval_users = eval_users_all\n",
    "        \n",
    "    print(f\"Используемые пользователи для оценки: {len(eval_users)}\")\n",
    "    \n",
    "    if len(eval_users) == 0:\n",
    "        raise RuntimeError(\"Нет пользователей для оценки после фильтрации: уменьшите TOP_CANDIDATES или порог.\")\n",
    "\n",
    "    # Оценка базовой модели популярности\n",
    "    print(\"Вычисляем метрики для базовой модели популярности...\")\n",
    "    pop_metrics = compute_popularity_metrics(train_df, test_df, top_candidates, eval_users, TOPK_LIST, RATING_THRESHOLD)\n",
    "    pop_out = os.path.join(OUT_DIR, \"eval_metrics_popularity.csv\")\n",
    "    pop_metrics.to_csv(pop_out, index=False)\n",
    "    print(f\"Сохранены метрики популярности в: {pop_out}\")\n",
    "\n",
    "    # Оценка ItemCF\n",
    "    print(\"Вычисляем метрики для ItemCF (может занять время)...\")\n",
    "    itemcf_metrics = compute_vectorized_itemcf(train_df, test_df, top_candidates, eval_users, TOPK_LIST, RATING_THRESHOLD)\n",
    "    itemcf_out = os.path.join(OUT_DIR, \"eval_metrics_itemcf.csv\")\n",
    "    itemcf_metrics.to_csv(itemcf_out, index=False)\n",
    "    print(f\"Сохранены метрики ItemCF в: {itemcf_out}\")\n",
    "\n",
    "    # Оценка SVD\n",
    "    print(\"Вычисляем метрики для SVD (TruncatedSVD)...\")\n",
    "    try:\n",
    "        svd_metrics = compute_svd_metrics(train_df, test_df, top_candidates, eval_users, TOPK_LIST, RATING_THRESHOLD, SVD_FACTORS)\n",
    "        svd_out = os.path.join(OUT_DIR, \"eval_metrics_svd.csv\")\n",
    "        svd_metrics.to_csv(svd_out, index=False)\n",
    "        print(f\"Сохранены метрики SVD в: {svd_out}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Вычисление метрик SVD не удалось: {e}\")\n",
    "        svd_metrics = pd.DataFrame([])\n",
    "\n",
    "    # Объединяем все результаты\n",
    "    frames = []\n",
    "    if not pop_metrics.empty: frames.append(pop_metrics)\n",
    "    if not itemcf_metrics.empty: frames.append(itemcf_metrics)\n",
    "    if not svd_metrics.empty: frames.append(svd_metrics)\n",
    "    \n",
    "    final = pd.concat(frames).sort_values(['K','model']).reset_index(drop=True)\n",
    "    final_out = os.path.join(OUT_DIR, \"eval_metrics_final_combined.csv\")\n",
    "    final.to_csv(final_out, index=False)\n",
    "    print(f\"Сохранены объединенные метрики в: {final_out}\")\n",
    "    print(f\"\\nФинальные метрики:\\n{final.to_string(index=False)}\")\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eef6d3-28d7-4a13-9481-4dc7114f767d",
   "metadata": {},
   "source": [
    "#### Выводим результаты\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "738d00f1-31c7-4367-8f16-835c824a6ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ЗАПУСК ОЦЕНКИ РЕКОМЕНДАТЕЛЬНЫХ СИСТЕМ\n",
      "==================================================\n",
      "Начинаем оценку рекомендательных систем...\n",
      "Делаем leave-one-out разделение...\n",
      "Тренировочные данные: 928332, Тестовые данные: 53424, время: 13.3 сек\n",
      "Топ кандидатов (количество): 2000\n",
      "Доступные пользователи для оценки: 739\n",
      "Используемые пользователи для оценки: 739\n",
      "Вычисляем метрики для базовой модели популярности...\n",
      "Сохранены метрики популярности в: .\\eval_metrics_popularity.csv\n",
      "Вычисляем метрики для ItemCF (может занять время)...\n",
      "Сохранены метрики ItemCF в: .\\eval_metrics_itemcf.csv\n",
      "Вычисляем метрики для SVD (TruncatedSVD)...\n",
      "Сохранены метрики SVD в: .\\eval_metrics_svd.csv\n",
      "Сохранены объединенные метрики в: .\\eval_metrics_final_combined.csv\n",
      "\n",
      "Финальные метрики:\n",
      "     model  K  precision_mean  recall_mean  ndcg_mean  n_eval_users\n",
      "    ItemCF  5        0.046549     0.232747   0.182279           739\n",
      "Popularity  5        0.000000     0.000000   0.000000           739\n",
      "       SVD  5        0.032148     0.160740   0.122866           703\n",
      "    ItemCF 10        0.029364     0.293640   0.201852           739\n",
      "Popularity 10        0.000000     0.000000   0.000000           739\n",
      "       SVD 10        0.023898     0.238976   0.148753           703\n",
      "    ItemCF 20        0.018877     0.377537   0.222960           739\n",
      "Popularity 20        0.000000     0.000000   0.000000           739\n",
      "       SVD 20        0.016714     0.334282   0.172716           703\n",
      "\n",
      "Визуализация результатов оценки...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ЗАПУСК ОЦЕНКИ РЕКОМЕНДАТЕЛЬНЫХ СИСТЕМ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Запускаем оценку на ваших данных ratings\n",
    "final_metrics = evaluate_recommendation_systems(ratings)\n",
    "\n",
    "# Визуализация результатов\n",
    "print(\"\\nВизуализация результатов оценки...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd56006-16cb-4441-851b-ac4b574b9a34",
   "metadata": {},
   "source": [
    "#### Анализ результатов рекомендательных систем\n",
    "\n",
    "Модель Item-Based Collaborative Filtering продемонстрировала наилучшие результаты среди всех протестированных подходов. Ее метрики качества составляют: Precision@5 - 4.65%, Recall@5 - 23.27% и nDCG@5 - 18.23%, что значительно превосходит другие модели.\n",
    "\n",
    "SVD-модель показала умеренные результаты с Precision@5 3.21%, Recall@5 16.07% и nDCG@5 12.29%, но существенно отстает от ItemCF (на 45-48% по всем метрикам).\n",
    "\n",
    "Popularity-модель показала нулевые результаты по всем метрикам, поскольку тестовые книги не входили в топ-K самых популярных, что демонстрирует ограниченность неперсонализированных подходов.\n",
    "\n",
    "Преимущество Item-Based CF объясняется его способностью эффективно работать с локальными паттернами схожести между книгами, не требуя глобального обучения как SVD-модели, что особенно важно в условиях разреженных данных.\n",
    "\n",
    "SVD-модель столкнулась с трудностями, возможно из-за недостаточного количества факторов или объема данных для обучения качественных скрытых представлений."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1c8c6d-cd1c-473a-b8a1-f5e7902691e1",
   "metadata": {},
   "source": [
    "### Этап 6. Гибридизация и выводы\n",
    "По результатам сравнения трёх реализованных моделей лучшими метриками (Precision@5 = 4.65%, Recall@5 = 23.27%, nDCG@5 = 18.23%) показала себя модель ItemCF. Она эффективно выявляет схожие предпочтения пользователей, но имеет недостатки: плохо работает для новых книг (проблема «холодного старта») и для пользователей с малым числом оценок.\n",
    "\n",
    "Чтобы компенсировать эти слабые стороны, предлагается гибридный подход:\n",
    "\n",
    "Основная модель: ItemCF — обеспечивает качественную персонализацию и находит книги, похожие на уже понравившиеся.\n",
    "\n",
    "Контентная модель (Content-Based) — использует TF-IDF векторизацию описаний книг и подбирает книги с похожим содержанием. Применяется для новых книг или когда пользователь поставил мало оценок.\n",
    "\n",
    "SVD-модель — используется как дополнительный сигнал для улучшения разнообразия рекомендаций и работы с пользователями, имеющими уникальные паттерны поведения.\n",
    "\n",
    "Popularity — добавляется как fallback-механизм для рекомендации проверенных популярных книг при полном отсутствии данных о пользователе.\n",
    "\n",
    "Финальный взвешенный гибрид вычисляет общую оценку.\n",
    "Такая схема сохраняет преимущества ItemCF, но делает систему устойчивой к холодному старту и повышает разнообразие рекомендаций.\n",
    "\n",
    "#### Обоснование выбора гибридного подхода\n",
    "\n",
    "Проблема холодного старта:\n",
    "ItemCF не может рекомендовать новые книги, так как у них нет оценок.\n",
    "Контентная часть решает это, используя текстовые признаки книги.\n",
    "\n",
    "Недостаток данных о пользователях:\n",
    "При малом числе оценок ItemCF не даёт устойчивых рекомендаций.\n",
    "Здесь помогает популярность и контентная близость.\n",
    "\n",
    "##### Сильные стороны разных подходов:\n",
    "ItemCF — персонализация, качество, понятность.\n",
    "Content-Based — покрытие новых книг, повышение разнообразия.\n",
    "Popularity — стабильная база рекомендаций для новых пользователей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4ae541-afba-4541-8bae-5b8c3682e697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf0ffc8e-d1b5-41f5-aa7a-c0a298afdfff",
   "metadata": {},
   "source": [
    "###  Итоговый проект"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac4babb-6052-42f3-a2c9-d9819f4791db",
   "metadata": {},
   "source": [
    "Этап 1. Улучшенная подготовка данных\n",
    "\n",
    "Создание расширенных признаков:\n",
    "\n",
    "Признаки пользователей: средний рейтинг, количество оценок, активность.\n",
    "Признаки книг: популярность, разнообразие оценок, тематические категории.\n",
    "Признаки взаимодействий: схожесть с историей пользователя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "290c2801-e6af-473c-9ca7-6ecc1173b205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Признаки пользователей\n",
    "user_features = ratings.groupby('user_id').agg(\n",
    "    user_mean_rating=('rating', 'mean'),\n",
    "    user_rating_count=('rating', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Признаки книг \n",
    "book_features = ratings.groupby('book_id').agg(\n",
    "    book_mean_rating=('rating', 'mean'),\n",
    "    book_rating_count=('rating', 'count')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8efd4f2d-9128-48b3-9e8a-86bf11254c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим данные из books_with_tags (например, количество отзывов и год публикации)\n",
    "book_extra = books_with_tags[['book_id', 'authors', 'original_publication_year', \n",
    "                              'average_rating', 'ratings_count', 'work_ratings_count']]\n",
    "book_features = book_features.merge(book_extra, on='book_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d4881b35-f767-4a10-ba2d-ea2e925c10a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для каждого (user, book) считаем схожесть книги с историей пользователя\n",
    "# Для ускорения используем кэширование user->list(book_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "313f2fa7-73c5-4334-a74a-b1c424b1638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Матрица TF-IDF и книги в том же порядке\n",
    "tfidf_books = books_with_tags[['book_id']].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "076771d4-2360-4b29-867e-f5d2176514ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#book_id -> индекс в TF-IDF\n",
    "book_id_to_idx = {bid: idx for idx, bid in enumerate(tfidf_books['book_id'])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3e623d24-d884-4b7d-842b-59de1611a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_profile_similarity(user_id):\n",
    "    \"\"\"Возвращает среднюю косинусную схожесть книги с историей пользователя.\"\"\"\n",
    "    user_books = ratings[ratings['user_id'] == user_id]['book_id'].values\n",
    "    user_idxs = [book_id_to_idx[b] for b in user_books if b in book_id_to_idx]\n",
    "    if not user_idxs:\n",
    "        return None\n",
    "    # Средний вектор пользователя (приводим к np.array)\n",
    "    user_vector = np.asarray(tfidf_matrix[user_idxs].mean(axis=0))\n",
    "    # Косинусная схожесть с каждой книгой\n",
    "    sims = cosine_similarity(user_vector, tfidf_matrix).flatten()\n",
    "    return sims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a41c5614-b9eb-4a9b-b39b-f5017afc99cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для ускорения создаём кэш схожестей\n",
    "user_similarity_cache = {}\n",
    "for uid in ratings['user_id'].unique():\n",
    "    sims = user_profile_similarity(uid)\n",
    "    if sims is not None:\n",
    "        user_similarity_cache[uid] = sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "25e0f024-2026-47ac-b482-230d6925e0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для извлечения признака \"схожесть с историей пользователя\"\n",
    "def get_interaction_features(row):\n",
    "    uid, bid = row['user_id'], row['book_id']\n",
    "    if uid not in user_similarity_cache or bid not in book_id_to_idx:\n",
    "        return np.nan\n",
    "    sims = user_similarity_cache[uid]\n",
    "    return sims[book_id_to_idx[bid]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "33931f87-6a3b-4635-b414-46b097524909",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['similarity_with_user_profile'] = ratings.apply(get_interaction_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "017f7847-573c-48af-864d-5338d61561a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Финальное объединение \n",
    "hybrid_data = ratings.merge(user_features, on='user_id', how='left')\n",
    "hybrid_data = hybrid_data.merge(book_features, on='book_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e433bbb2-0590-40d5-ac5c-0a43395fa4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Размер итогового набора данных: (981756, 13)\n",
      "   book_id  user_id  rating  similarity_with_user_profile  user_mean_rating  \\\n",
      "0        1      314       5                      0.703703          3.585635   \n",
      "1        1      439       3                      0.535414          3.259887   \n",
      "2        1      588       5                      0.551915          3.618280   \n",
      "3        1     1169       4                      0.611868          3.770053   \n",
      "4        1     1185       4                      0.511998          3.473684   \n",
      "\n",
      "   user_rating_count  book_mean_rating  book_rating_count  \\\n",
      "0                181              4.24                100   \n",
      "1                177              4.24                100   \n",
      "2                186              4.24                100   \n",
      "3                187              4.24                100   \n",
      "4                190              4.24                100   \n",
      "\n",
      "                       authors  original_publication_year  average_rating  \\\n",
      "0  J.K. Rowling, Mary GrandPré                     2005.0            4.54   \n",
      "1  J.K. Rowling, Mary GrandPré                     2005.0            4.54   \n",
      "2  J.K. Rowling, Mary GrandPré                     2005.0            4.54   \n",
      "3  J.K. Rowling, Mary GrandPré                     2005.0            4.54   \n",
      "4  J.K. Rowling, Mary GrandPré                     2005.0            4.54   \n",
      "\n",
      "   ratings_count  work_ratings_count  \n",
      "0      1678823.0           1785676.0  \n",
      "1      1678823.0           1785676.0  \n",
      "2      1678823.0           1785676.0  \n",
      "3      1678823.0           1785676.0  \n",
      "4      1678823.0           1785676.0  \n"
     ]
    }
   ],
   "source": [
    "print(\" Размер итогового набора данных:\", hybrid_data.shape)\n",
    "print(hybrid_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "813c609f-8c1d-4311-b100-896d18d3acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ЭТАП 2: Построение гибридной системы рекомендаций \n",
    "#  Настройка весов в зависимости от типа пользователя\n",
    "\n",
    "def user_segment(user_id, ratings):\n",
    "    \"\"\"Определяем тип пользователя по количеству оценок.\"\"\"\n",
    "    n_ratings = ratings[ratings['user_id'] == user_id].shape[0]\n",
    "    if n_ratings <= 3:\n",
    "        return 'new'\n",
    "    elif n_ratings <= 15:\n",
    "        return 'low_activity'\n",
    "    else:\n",
    "        return 'active'\n",
    "\n",
    "# Весовые схемы для разных типов пользователей\n",
    "ENSEMBLE_WEIGHTS = {\n",
    "    'new':          {'itemcf': 0.0, 'content': 0.4, 'svd': 0.0, 'pop': 0.6},\n",
    "    'low_activity': {'itemcf': 0.5, 'content': 0.3, 'svd': 0.1, 'pop': 0.1},\n",
    "    'active':       {'itemcf': 0.6, 'content': 0.1, 'svd': 0.3, 'pop': 0.0}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d98aa9-a1ca-4905-b530-eeee613c3ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Функции получения кандидатов из разных моделей ----------\n",
    "\n",
    "def get_itemcf_scores(user_id, n=100):\n",
    "    try:\n",
    "        return itemcf_recommend(user_id, top_n=n)  # твоя существующая функция\n",
    "    except:\n",
    "        return pd.DataFrame(columns=['book_id', 'score'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
